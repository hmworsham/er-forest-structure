{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging East River Tree Stem Geolocation Points\n",
    "**Author:** 'Marshall Worsham' <br>\n",
    "**Creation Date:** '09/21/2020' <br>\n",
    "**Revision Date:** '12/22/2020' <br>\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1 - [Front matter](#front)<br>\n",
    "2 - [Libraries](#libraries)<br>\n",
    "3 - [Import reference table](#import)<br>\n",
    "4 - [Exploratory analysis](#eda)<br>\n",
    "5 - [Rename and move](#rename)<br>\n",
    "6 - [Prepare for append](#prep)<br>\n",
    "7 - [Append](#append)<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Front matter<a id='front'></a>\n",
    "\n",
    "This notebook contains markdown and code for post-processing point shapefiles generated from Trimble Geo7X GPS acquisitions in the East River domain. The script appends the `Site` name and `subdirectory` to each shapefile name, then selects all projected point shapefiles, groups them by `Site` name, and merges points from the same site. The result is a set of shapefiles containing tree geolocation points, one set for each site in the watershed where stem geolocations were acquired from 2018â€“2020. Most output files contain some extraneous points marking corners and errata, which are cleaned out in '00_EastRiver_Clean_Tree_GPSPoints.ipynb'. \n",
    "\n",
    "The script was developed in `Python 3.8.2` on a Macbook Pro 2014 running OSX 10.14.6.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries<a id='libraries'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join, getsize\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the working directory and list contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "directory = os.sep.join(['/Volumes', 'GoogleDrive', 'My Drive', 'Research', 'RMBL', 'Working_Files', 'Forest_Inventory_Dataset'])\n",
    "source_dir = os.sep.join([directory, 'Source'])\n",
    "scratch_dir = os.sep.join([directory, 'Scratch'])\n",
    "out_dir = os.sep.join([directory, 'Output'])\n",
    "gps_dir = os.sep.join(['/Volumes', 'GoogleDrive', 'My Drive', 'Research', 'RMBL', 'RMBL-East River Watershed Forest Data', 'Data', 'Inventory Plots', '02_Inventory_Plots_GPS_Data', '2021'])\n",
    "os.listdir(gps_dir)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import reference table<a id='reference'></a>\n",
    "First we import a CSV describing filenames and associated sites. Then we slice to create a simple list of filenames and the site at which the data inside those files were acquired.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "gps_index = pd.read_csv(os.sep.join([source_dir, 'EastRiver_GPS_Data_Index.csv']))\n",
    "gps_index.dropna(0, subset=['Site', 'Contents'], inplace=True)\n",
    "gps_index.loc[:, 'Filename':'Site'].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis<a id='eda'></a>\n",
    "Some simple exploratory analysis reveals see how many unique files are associated with each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "gps_index.groupby('Site').count()['Filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Scratch to set up the syntax for the function below that will relate filenames in the directory to filenames and site associations in the index dataframe\n",
    "gps_index_sites = gps_index.loc[:,'Filename':'Site']\n",
    "gps_index_sites.loc[gps_index_sites['Filename'] == 'WORSHAMM071610A'].iloc[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the filenames in all subdirectories of `directory` by walking the subdirectories and string-splitting on the last `/` in the path to isolate filenames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk(os.sep.join([gps_dir, '2021'])):\n",
    "    for filename in files:\n",
    "        subdir_name = subdir.rsplit('/', 1)[-1]\n",
    "        print(subdir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename and move<a id='rename'></a>\n",
    "The function below finds the name of the `subdirectory` that each shapefile lives in and finds the `Site` with which that subdirectory is associated. The function renames each shapefile by appending the `subdirectory` name and `Site` name to the filename, then moves all files into a single directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "gps_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk(gps_dir):\n",
    "    for filename in files:\n",
    "        gps_index_sites = gps_index.loc[:, 'Filename':'Site']\n",
    "        subdir_name = subdir.rsplit('/', 1)[-1]\n",
    "        index_sitename = str(gps_index_sites.loc[gps_index_sites['Filename'] == subdir_name, 'Site'].values).strip(\"[]\").strip(\"'\")\n",
    "        newname = subdir_name + '_' + index_sitename + '_' + filename\n",
    "        oldpath = subdir + os.sep + filename\n",
    "        newpath = subdir + os.sep + newname\n",
    "        #print(oldpath)\n",
    "        #print(newname)\n",
    "        #print(newpath)\n",
    "        os.rename(oldpath, newpath)\n",
    "        if not re.search('Line.+', filename) and not re.search('Area.+', filename) and not re.search('Icon.+', filename):\n",
    "            print(newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for append<a id='prep'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# list all files\n",
    "renamed_dir = os.path.join(scratch_dir, 'GPS_Data_2021_Renamed')\n",
    "allfiles = os.listdir(renamed_dir)\n",
    "allfiles[0:10]\n",
    "#allfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# generate a list of unique site names represented in the dataset\n",
    "sitelist = gps_index['Site'].unique().tolist()\n",
    "sitelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# filter only shapefiles containing point data types in the correct projection\n",
    "# the target filenames will contain the tag \"Project\" AND either of the strings \"Student\" or \"Point\"\n",
    "# filenames without \"Student\" and filenames containing \"Area\" and \"Line\" strings will be filtered out\n",
    "point_str = 'Point_'\n",
    "stud_str = 'Student'\n",
    "proj_str = '_Project'\n",
    "sf_allpoint = [i for i in allfiles if ((point_str in i or stud_str in i) and proj_str in i)]\n",
    "print(len(allfiles))\n",
    "print(len(sf_allpoint))\n",
    "sf_allpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# # manipulate the gps_index dataframe\n",
    "# notcorners = gps_index[~gps_index['Contents'].str.contains('corner')] # filter out names of subdirs containing corners\n",
    "# notcorners = notcorners['Filename'].to_list()\n",
    "# print(notcorners[:10])\n",
    "# print(len(sf_allpoint))\n",
    "# print(len(notcorners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# manipulate gps_index dataframe\n",
    "trees = gps_index[gps_index['Contents'].str.contains('tree')]\n",
    "trees = trees['Filename'].to_list()\n",
    "print(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# find files representing trees only, with .shp extension\n",
    "trees_allfiles = [i for i in sf_allpoint if any(ii in i for ii in trees)]\n",
    "trees_sf = [t for t in trees_allfiles if t.endswith('.shp')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(len(trees_sf))\n",
    "print(trees_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append<a id='append'></a>\n",
    "\n",
    "1. group files according to site name by finding common value from sitelist in `matches` string\n",
    "2. for each site, select the first shapefile and assign it as base object\n",
    "3. append all other shapefiles to the base object with `gpd.append()`\n",
    "4. project crs to wgs84 utm zone 13\n",
    "4. export the gpdf as a shapefile named: sitelist[i] + '_' + 'TreeStem_pts_WGS84UTM13.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# add full path to all filenames\n",
    "trees_sf_paths = [renamed_dir + os.sep + i for i in trees_sf]\n",
    "trees_sf_paths[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# group files by plot\n",
    "trees_sf_grouped = [[s for s in trees_sf_paths if key in s] for key in set(sitelist)]\n",
    "trees_sf_grouped = [i for i in trees_sf_grouped if len(i) != 0] # filter out a few artifact empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# output list of grouped tree shapefiles in directory\n",
    "trees_sf_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# aggregate, import, and append\n",
    "alltrees_gpdf = []\n",
    "for thing in trees_sf_grouped:\n",
    "    site_gpdf = []\n",
    "    for i in thing:\n",
    "        gpdf = gpd.read_file(i)\n",
    "        site_gpdf.append(gpdf)\n",
    "    alltrees = site_gpdf[0].append(site_gpdf[1:])\n",
    "    alltrees.to_crs(epsg = 32613, inplace = True)\n",
    "    alltrees = alltrees.loc[alltrees.geom_type == 'Point']\n",
    "    site = [s for s in sitelist if s in thing[0]][0]\n",
    "    alltrees['Site'] = site\n",
    "    alltrees.to_file(os.path.join(scratch_dir, 'GPS_Data_2021_MERGEDBYPLOT', site + '.shp'))\n",
    "    alltrees_gpdf.append(alltrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "alltrees_gpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eastriver",
   "language": "python",
   "name": "eastriver"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
