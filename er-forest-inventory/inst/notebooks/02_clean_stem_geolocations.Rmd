---
title: "Merge Tree Stem GPS Points"
author: "Marshall Worsham - UC Berkeley - worsham@berkeley.edu"
date: "2023-02-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE)
```

---

## Contents

1 - [Front matter](#front)<br>
2 - [Workspace configuration](#workspace)<br>
3 - [Import stem geolocation shapefiles](#stems)<br>
4 - [Import inventory data from Google Drive](#inv)<br>
5 - [Clean data](#clean)<br>
6 - [Merge inventory records with geotag records](#merge)<br>
7 - [Create new points from geotag association notes](#newpoints)<br>
8 - [Row bind geotag records and newly generated points](#bind)<br>
9 - [Split by site](#split)<br>
10 - [Write out to shapefile](#write)<br>

---

## Front matter <a id='front'></a>

This notebook contains markdown and code for post-processing point shapefiles generated from Trimble Geo7X GPS acquisitions in the East River domain. The input is a set of shapefiles containing tree geolocation points, one set for each site in the watershed where stem geolocations were acquired from 2018â€“2020. The script appends the `Site` name and `subdirectory` to each shapefile name, then selects all projected point shapefiles, groups them by `Site` name, and merges points from the same site. It then filters out undesired points (e.g., plot corners and plot edges).

This was originally written in Python on 2020-09-21 and translated to R for more efficient processing of shapefiles and better handling of Google Drive imports on 2023-02-07.

## Workspace configuration <a id='workspace'></a>
Load local config file with urls, directory paths. Load local helper functions. 
```{r workspace, include=F}
# Load config
config <- config::get(file=file.path('config', 'config.yml'))

# Load local helper functions and packages
devtools::load_all()
load.pkgs(config$pkgs)

# Configure drive oauth
drive_auth_configure(path=config$driveauth, api_key=readLines(config$drivekey))
drive_auth(email=config$email)
```

## Ingest tree stem geolocation shapefiles<a id='stems'></a>
```{r ingeststems, echo=F}
treedir <- file.path(config$dat_int, 'GPS_Data_Merged_2021')
trees <- lapply(
  list.files(treedir, pattern='shp', full.names=T),
  st_read
  )
```

## Ingest inventory data from Google Drive <a id='inv'></a>
```{r ingestinv, echo=F}
invsheets <- drive_find(pattern=config$extdata$invpattern, type='spreadsheet')
invnames <- invsheets$name
invids <- invsheets$id
inventory <- lapply(invnames, load.inventory)
```

## Clean data <a id='clean'></a>

Clean up tree stem geolocation data
```{r cleantrees}
# Row bind tree geolocation data
trees.df <- bind_rows(trees)
rownames(trees.df) <- NULL

# Assign tag numbers recorded in wrong field where possible
trees.df[is.na(trees.df$Other),]$Other <- trees.df[is.na(trees.df$Other),]$Other2
colnames(trees.df)[which(names(trees.df) %in% c('Other', 'Other2'))] <-
  c('Tag_Number',
    'Sp_Code')
trees.df$Tag_Number <- as.numeric(trees.df$Tag_Number)

# Create a concatenated site-tag column to make unique site-tree IDs
# (A few tag sequences occur in more than one plot)
trees.df$SiTag <- paste0(trees.df$Site, '_', trees.df$Tag_Number)

# Find duplicate records and drop those not needed
# dupes <- trees.df[duplicated(trees.df$SiTag),]
# dupes <- trees.df[trees.df$Tag_Number %in% dupes$Tag_Number,]

# Review
head(trees.df)
```

Clean up inventory data.
```{r cleaninv}
# Row bind inventory data
inv.df <- bind_rows(inventory)
rownames(inv.df) <- NULL

# Create a concatenated site-tag column to make unique site-tree IDs
# (A few tag sequences occur in more than one plot)
inv.df$SiTag <- paste0(inv.df$Site_Name, '_', inv.df$Tag_Number)

# Review
head(inv.df)

# Filter to 2021 records only
data21 <- inv.df %>%
  filter((Census_End > '2021-01-01') & (Census_End < '2021-12-31'))

# Check
unique(data21$Census_Start)
unique(data21$Site_Name)
dim(data21)
```

## Merge inventory records with geotag records <a id='merge'></a>
``` {r merge}
invtrees <- merge(data21, trees.df, by = 'SiTag', all = T)
invtrees.sf <- st_as_sf(invtrees)
```

## Create new points from geotag association notes <a id='newpoints'></a>
```{r newpoints}
new.trees <- make.new.point(invtrees.sf)
```

## Row bind geotag records and newly generated points <a id='bind'></a> 
```{r bindoldnew}
# invtrees.sf <- invtrees.sf[st_is_empty(invtrees.sf),]
alltrees <- bind_rows(trees.df, new.trees)
rownames(alltrees) <- NULL
alltrees <- alltrees[c(
  'Site',
  'Tag_Number', 
  'Sp_Code',
  'Latitude',
  'Longitude',
  'GNSS_Heigh',
  'Horz_Prec',
  'Vert_Prec',
  'Std_Dev',
  'GPS_Time',
  'GPS_Date',
  'Rcvr_Type',
  'Corr_Type',
  'Max_PDOP',
  'Max_HDOP',
  'Filename',
  'Geotag_Association',
  'Comment',
  'geometry')]
```

## Split by site <a id='split'></a>
```{r split}
# Remove duplicate entries, selecting the one with best horizontal precision
alltrees <- alltrees %>%
  group_by(Site, Tag_Number) %>%
  arrange(Horz_Prec, .by_group=T) %>%
  filter(row_number()==1)

# Split sf by site
trees.by.site <- split(alltrees, with(alltrees, Site), drop = F)
```

## Write out to shapefile <a id='write'></a>
```{r write}
lapply(trees.by.site, write.trees.by.site)
```
